name: Ejecutar scraper de noticias

on:
  schedule:
    - cron: "0 * * * *" # Cada hora
  workflow_dispatch:

jobs:
  run-scraper:
    runs-on: ubuntu-latest

    steps:
      # 1️⃣ Clona el repo completo (necesario para poder hacer commits)
      - name: Checkout del repositorio
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0  # importante para poder hacer push

      # 2️⃣ Configura Python
      - name: Configurar Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      # 3️⃣ Instala dependencias
      - name: Instalar dependencias
        run: pip install -r requirements.txt

      # 4️⃣ Ejecuta el scraper
      - name: Ejecutar scraper
        env:
          URL: ${{ vars.URL }}
          KEYWORDS: ${{ vars.KEYWORDS }}
          TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
          TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
        run: python scraper_alerts.py

      # 5️⃣ Guarda el archivo actualizado en el repo
      - name: Guardar archivo actualizado
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add sent_alerts.txt || true
          git diff --staged --quiet || (git commit -m "chore: update sent_alerts.txt [skip ci]" && git push)
