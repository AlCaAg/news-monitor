name: News Scraper

on:
  schedule:
    # Ejecutar cada 30 minutos
    - cron: "*/30 * * * *"
  workflow_dispatch: # Permite ejecuciÃ³n manual desde GitHub

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: ğŸ§© Clonar el repositorio
        uses: actions/checkout@v4

      - name: âš™ï¸ Configurar Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: ğŸ“¦ Instalar dependencias
        run: |
          python -m pip install --upgrade pip
          pip install requests beautifulsoup4

      - name: ğŸª¶ Crear archivo de cache si no existe
        run: |
          if [ ! -f sent_alerts.txt ]; then
            echo "Creando archivo sent_alerts.txt vacÃ­o..."
            touch sent_alerts.txt
          fi

      - name: ğŸ’¾ Restaurar cache de alertas enviadas
        uses: actions/cache@v3
        with:
          path: sent_alerts.txt
          key: sent-alerts-cache

      - name: ğŸš€ Ejecutar scraper de noticias
        env:
          URL: ${{ secrets.URL }}
          KEYWORDS: ${{ secrets.KEYWORDS }}
          TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
          TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
        run: python scraper_alerts.py

      - name: ğŸ’¾ Guardar cache actualizada
        if: always()
        uses: actions/cache@v3
        with:
          path: sent_alerts.txt
          key: sent-alerts-cache
